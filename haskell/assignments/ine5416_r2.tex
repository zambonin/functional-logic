\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[a4paper, left=20mm, right=20mm, top=20mm, bottom=20mm]{geometry}

\begin{document}

\subsubsection*{INE5416 - Paradigmas de Programação (2015/2) \\
    Gustavo Zambonin \\
    Relatório 2 - Estrutura das linguagens
}

\subsubsection*{Questão 1}
\begin{itemize}
    \item Yacc é um programa que constrói a parte de um compilador responsável por analisar a parte sintática de um código-fonte qualquer, baseado em uma gramática de livre contexto (um conjunto de regras de produção para palavras numa linguagem formal). Desenvolvido na AT\&T em meados da década de 1970, existem diversas versões do Yacc, sejam elas abertas ou não.

    \item Lex é um programa que gera analisadores léxicos. Geralmente é utilizado em conjunto com o Yacc, entregando ao usuário o código-fonte do analisador na linguagem de programação C. Recomenda-se produzir a entrada do analisador sintático com este programa a partir de expressões regulares. Internamente, ele funciona através de autômatos finitos determinísticos (máquinas que aceitam linguagens regulares).

    \item Flex é a versão aberta do Lex. Funciona de maneira similar, de modo a ler \textit{tokens} e reconhecê-los como certas funções da linguagem de programação. Estes \textit{tokens} podem ser operadores, palavras-chave, identificadores, números etc.. Esta é a primeira fase do funcionamento de um compilador atualmente.

    \item Bison é a versão aberta do Yacc. Novamente, funciona de maneira similar. Estes programas executam a segunda fase do funcionamento de um compilador, analisando se a sequência de \textit{tokens} faz sentido para a sintaxe especificada pela gramática. Estas ferramentas são essenciais para a formalização da descrição de uma linguagem de programação e intrínsecas ao funcionamento de computadores atualmente.
\end{itemize}

\subsubsection*{Questão 2}
\begin{itemize}
    \item \texttt{scan.l} é uma tabela de expressões regulares e fragmentos de código, que é transformada então para um programa que lê uma entrada qualquer, dividindo-a em partes que assemelham-se às expressões dadas. Este reconhecimento é feito utilizando um autômato gerado pelo analisador léxico. Nota-se, por exemplo, que o programa reconhecerá diversos \textit{tokens} diferentes como sendo constantes decimais ou hexadecimais, mas para uma palavra reservada, a função correspondente será sempre executada.

    \begin{verbatim}
    0[xX]{H}+{IS}?      { count(); return(CONSTANT); }
    0{D}+{IS}?          { count(); return(CONSTANT); } \end{verbatim}
    
    Ex.: neste caso, uma constante pode ser reconhecida como hexadecimal ou decimal.

    \item \texttt{y.tab.h} nada mais é do que um cabeçalho que especifica diversas funções específicas à linguagem de programação C e nomeia-as de modo amigável.

    \item \texttt{gram.y} decide exatamente como o compilador deve entender o que é escrito a partir desta ordem sintática, incluindo a ordem dos \textit{tokens} e diversas variações do que pode ser expressado, através de uma gramática.

    \begin{verbatim}
    iteration_statement
        : WHILE '(' expr ')' statement
        | DO statement WHILE '(' expr ')' ';'
        | FOR '(' ';' ';' ')' statement
        | FOR '(' ';' ';' expr ')' statement
        | FOR '(' ';' expr ';' ')' statement
        | FOR '(' ';' expr ';' expr ')' statement
        | FOR '(' expr ';' ';' ')' statement
        | FOR '(' expr ';' ';' expr ')' statement
        | FOR '(' expr ';' expr ';' ')' statement
        | FOR '(' expr ';' expr ';' expr ')' statement
        ; \end{verbatim}

    Ex.: em \texttt{iteration\_statement}, observa-se que é possível abrigar diversas expressões booleanas dentro de uma simples operação FOR, enquanto existe apenas uma possibilidade para a operação WHILE. 
\end{itemize}

\end{document}